{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c3f1910",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mally\\AppData\\Local\\Temp\\ipykernel_23452\\3524297253.py:1: DeprecationWarning: The distutils package is deprecated and slated for removal in Python 3.12. Use setuptools or check PEP 632 for potential alternatives\n",
      "  from distutils.command import config\n"
     ]
    }
   ],
   "source": [
    "from distutils.command import config\n",
    "\n",
    "def random_search(problem, function_evaluations=150, **kwargs):\n",
    "\n",
    "    history = []\n",
    "    configs = []\n",
    "\n",
    "    RANGES = GET_RANGES(problem) \n",
    "\n",
    "    for j in range(function_evaluations):\n",
    "        config={}\n",
    "        \n",
    "        for i in RANGES:\n",
    "            # If there is a condition, check if it holds.\n",
    "            # If not, skip this hyperparameter\n",
    "            if(condition(RANGES, config, i)):\n",
    "                config[i] = math.nan\n",
    "                continue\n",
    "            \n",
    "            a = RANGES[i]['range'][0] \n",
    "            b = RANGES[i]['range'][1] \n",
    "            \n",
    "            # If uniform\n",
    "            if(RANGES[i]['sample']==0):\n",
    "                if (RANGES[i][\"type\"] == 0):\n",
    "                    value=np.random.choice(RANGES[i]['range']) \n",
    "                    config[i]=value  \n",
    "                elif (RANGES[i][\"type\"] == 1):\n",
    "                    value=np.random.uniform(a, b) \n",
    "                    config[i]=value\n",
    "                else:\n",
    "                    value=np.random.randint(a, b+1) \n",
    "                    config[i]=value\n",
    "            # Else log        \n",
    "            else:\n",
    "                value=np.random.uniform(np.log(a), np.log(b)) \n",
    "                value = np.exp(value)\n",
    "                if RANGES[i]['type'] == 2:\n",
    "                    value = round(value)\n",
    "                config[i]=value # exponentiate value back \n",
    "      \n",
    "        configs.append(config)\n",
    "        history.append(GET_CONFIG_PERFORMANCE(config, problem))\n",
    "\n",
    "    return history, configs\n",
    "\n",
    "# Function for checking if hyperparameter has a condition and whether it holds\n",
    "def condition(ranges, config, i):\n",
    "        if('condition' in ranges[i]):\n",
    "            if (ranges[i]['condition'](config) == False):\n",
    "                return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "497f7319",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import GET_CONFIG_PERFORMANCE, GET_RANGES, SampleType, ParamType,normal_dist # make sure to make use of ParamType and SampleType in your code\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from scipy.stats import truncnorm\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# Check if current hyperparameter is active, specifically for nlayers\n",
    "def condition_check(x_star, i): \n",
    "    if 'nlayers' in x_star.keys():\n",
    "        layers = x_star['nlayers']\n",
    "        if i[-1].isdigit():\n",
    "            if int(i[-1]) > layers:\n",
    "                return True\n",
    "\n",
    "# n = number of candidate samples\n",
    "def tpe2(problem, function_evaluations=150, random_warmup=10, gamma=0.5, n=10, **kwargs):\n",
    "\n",
    "    RANGES = GET_RANGES(problem) \n",
    "    \n",
    "    # Initial warm-up using random search\n",
    "    loss,configs=random_search(problem,random_warmup)    \n",
    "    \n",
    "    hyperparameters = to_df(configs, loss)    \n",
    "        \n",
    "    for k in range(function_evaluations):\n",
    "        \n",
    "        good_df, bad_df = good_bad(gamma, hyperparameters)\n",
    "        # Initialize best found configuration\n",
    "        x_star = {}\n",
    "        \n",
    "        # Iterate through each hyperparameter\n",
    "        for i in good_df.columns.difference(['loss']): \n",
    "            # Seperate into good and bad samples\n",
    "            x = good_df[i].dropna().values.tolist()\n",
    "            y = bad_df[i].dropna().values.tolist()\n",
    "            # Add back together for sampling\n",
    "            full = x + y\n",
    "            # Define truncation boundaries\n",
    "            a = RANGES[i]['range'][0]\n",
    "            b = RANGES[i]['range'][1]\n",
    "            # Check if current hyperparamter is active    \n",
    "            if(condition_check(x_star, i)):\n",
    "                x_star[i] = math.nan\n",
    "                continue\n",
    "            \n",
    "            # If categorical\n",
    "            if RANGES[i]['type'] == 0:\n",
    "                samples = sample_uniform(RANGES[i], n)\n",
    "                # Calculate probability density of the samples\n",
    "                lx = categorical_pdf(x, samples)\n",
    "                gx = categorical_pdf(y, samples)\n",
    "                EI = calculate_EI(lx, gx)\n",
    "                EI_max = np.argmax(EI)\n",
    "                value = samples[EI_max]\n",
    "                x_star[i] = value\n",
    "                \n",
    "            else:\n",
    "                # If sample type is log-unfirom\n",
    "                if RANGES[i]['sample'] == 1:\n",
    "                    x = np.log(x)\n",
    "                    y = np.log(y)\n",
    "                    full = np.log(full)\n",
    "                    a, b = np.log(a), np.log(b)\n",
    "                    \n",
    "                # Sort because we need the standard deviation to the furthest neighbour\n",
    "                x.sort()                  \n",
    "                y.sort()\n",
    "                full.sort()\n",
    "                # Calculate sigma for getting the density from the Gaussians\n",
    "                std_full = scales(full, a, b)\n",
    "                # Sample from truncated gaussians\n",
    "                samples = sample_truncnorm(a, b, full, std_full, n)\n",
    "                # In case l(x) or g(x) does not contain samples: the sigma is 0\n",
    "                max_sd, max_sd_y = 0, 0\n",
    "                if len(x) > 0:\n",
    "                    max_sd = scales(x, a, b)\n",
    "                if len(y) > 0:\n",
    "                    max_sd_y = scales(y, a, b)\n",
    "                # Calculate EI\n",
    "                EI = get_EI(samples, x, y, a, b, max_sd, max_sd_y, gamma)\n",
    "                EI_max = np.argmax(EI)\n",
    "                value = samples[EI_max]\n",
    "                # If sample type is log-uniform, exponentiate\n",
    "                if RANGES[i]['sample'] == 1:\n",
    "                    value = np.exp(value)\n",
    "                # If hp type is int, round\n",
    "                if RANGES[i]['type'] == 2:\n",
    "                    value = round(value)      \n",
    "                x_star[i] = value\n",
    "        # Calculate loss and append to observations\n",
    "        x_star['loss'] = GET_CONFIG_PERFORMANCE(x_star, problem) \n",
    "        hyperparameters = hyperparameters.append(x_star, ignore_index=True)            \n",
    "    # Seperate all found hyperparameters for plotting EI, l(x) and g(x)\n",
    "    x_final, y_final = good_bad(gamma, hyperparameters)\n",
    "    EI_plot1 = plot_EI(x_final.iloc[:,0].values,y_final.iloc[:,0].values, a, b, gamma)\n",
    "    EI_plot2 = plot_EI(x_final.iloc[:,1].values, y_final.iloc[:,1].values, a, b, gamma)\n",
    "    \n",
    "    l_x_plot_h1 = pdf_array(x_final.iloc[:,0].values,a,b)\n",
    "    l_x_plot_h2 = pdf_array(x_final.iloc[:,1].values,a,b)\n",
    "    g_x_plot_h1 = pdf_array(y_final.iloc[:,0].values,a,b)\n",
    "    g_x_plot_h2 = pdf_array(y_final.iloc[:,1].values,a,b)\n",
    "    \n",
    "    best_hp = hyperparameters.iloc[hyperparameters['loss'].idxmin()]\n",
    "    return hyperparameters, best_hp, x_final, y_final, EI_plot1, EI_plot2,l_x_plot_h1,g_x_plot_h1,l_x_plot_h2,g_x_plot_h2\n",
    "\n",
    "# Returns an array with the values for EI\n",
    "def plot_EI(x, y, a, b, gamma):\n",
    "    space = np.linspace(a, b, 100)\n",
    "    l_x = pdf_array(x, a, b)\n",
    "    g_x = pdf_array(y, a, b)\n",
    "    # If a value in g(x) == 0, divide by 1\n",
    "    # So i.e: if a samples hyperparameter is not in g(x), its EI = its pd in l(x)\n",
    "    g_x[g_x == 0] = 1\n",
    "    plot = (gamma + (1-gamma)*(l_x/g_x))\n",
    "    return plot\n",
    "\n",
    "# Returns an array with the values for a pdf\n",
    "def pdf_array(x, a, b):\n",
    "    scales_ = []\n",
    "    space = np.linspace(a, b, 100)\n",
    "    scales_ = scales(x, a, b)\n",
    "    array = np.zeros_like(space)\n",
    "    # Iterate through each sample\n",
    "    for i in range(len(x)):\n",
    "        dist = truncnorm(a, b,loc=x[i], scale=scales_[i])\n",
    "        # Get pdf values for its truncated Gaussian \n",
    "        array += dist.pdf(space)\n",
    "    return array\n",
    "\n",
    "# Get EI for a single value of a hyperparameter\n",
    "def get_EI(samples, x, y, a, b, max_sd, max_sd_y, gamma):\n",
    "    EI = []\n",
    "    for j in range(len(samples)):   \n",
    "        # Set the density to 1, incase l(x) and/or g(x) is zero\n",
    "        pd_lx = 0\n",
    "        pd_gx = 1\n",
    "        if len(x) > 0:\n",
    "            pd_lx = get_pdf(samples[j], x, a, b, max_sd)     \n",
    "        if len(y) > 0:\n",
    "            pd_gx = get_pdf(samples[j], y, a, b, max_sd_y)\n",
    "        if pd_gx == 0:\n",
    "            pd_gx = 1\n",
    "        # Calculate EI\n",
    "        value = (gamma + (1-gamma)*(pd_lx/pd_gx))\n",
    "        EI.append(value)\n",
    "    return EI\n",
    "\n",
    "def return_node_list(x):\n",
    "    nodes= []\n",
    "    for i in x.keys():\n",
    "        if 'nodes_in_layer' in i:\n",
    "            nodes.append(x[i])\n",
    "    return nodes\n",
    "        \n",
    "def to_df(configs, loss):\n",
    "\n",
    "    hyper_parameters=pd.DataFrame(columns=[\"configs\",\"loss\"])\n",
    "    hyper_parameters[\"configs\"]=configs\n",
    "    hyper_parameters[\"loss\"]=loss\n",
    "    \n",
    "    hyper_parameters_1 = (hyper_parameters[\"configs\"].apply(pd.Series))\n",
    "    hyper_parameters_1['loss'] = hyper_parameters[\"loss\"]\n",
    "    \n",
    "    \n",
    "    return hyper_parameters_1\n",
    "            \n",
    "# Function for dividing samples into good and bad dataframes    \n",
    "def good_bad(gamma, hyper_parameters):\n",
    "\n",
    "    sorted_df=(hyper_parameters.sort_values(by=[\"loss\"])).reset_index(drop=True)\n",
    "    \n",
    "    index_value=int(gamma*(sorted_df.shape[0]))\n",
    "    \n",
    "    good_df = sorted_df.iloc[:index_value]\n",
    "    bad_df = sorted_df.iloc[index_value:sorted_df.shape[0]]\n",
    "            \n",
    "    return good_df, bad_df\n",
    "\n",
    "def sample_truncnorm(a, b, x, sd, n):\n",
    "    index = np.random.choice(range(len(x)))\n",
    "    a, b = (a - x[index]) / sd[index], (b - x[index]) / sd[index]\n",
    "    samples = stats.truncnorm.rvs(a, b, loc=x[index], scale=sd[index], size=n)\n",
    "    return samples\n",
    "\n",
    "def get_pdf(x_i, x, a, b, sd):\n",
    "    n = len(x)\n",
    "    total = 0\n",
    "    \n",
    "    for i in range(n):\n",
    "        mean = x[i]\n",
    "        sigma = sd[i]\n",
    "        a, b = (a - mean) / sigma, (b - mean) / sigma\n",
    "        total += stats.truncnorm.pdf(x_i, a, b, loc=mean, scale=sigma)\n",
    "       # if error == 'error':\n",
    "       #     print(x_i, a, b, mean, sigma)\n",
    "        \n",
    "    return total/n\n",
    "\n",
    "def scales(x, a, b):\n",
    "    if len(x) > 1:\n",
    "        diff = np.diff(x)\n",
    "    else:\n",
    "        diff = [0]\n",
    "    epsilon = (b-a)/min(100,len(x)+2)\n",
    "    scales = []\n",
    "    for i in range(0, len(diff)):\n",
    "        max_ = max(diff[i-1], diff[i], epsilon)\n",
    "        sigma = min(max_, b-a)\n",
    "        scales.append(sigma)        \n",
    "    scales.insert(0,min(max(diff[0], epsilon), b-a))\n",
    "    scales.insert(-1,min(max(diff[-1], epsilon), b-a))\n",
    "    \n",
    "    return scales\n",
    "\n",
    "def sample_uniform(hyperparameter, n):\n",
    "    sample = np.random.choice(hyperparameter['range'], n)    \n",
    "    return sample\n",
    "\n",
    "def normal_dist(x , mean , sd):\n",
    "    prob_density = (np.pi*sd) * np.exp(-0.5*((x-mean)/sd)**2)\n",
    "    return prob_density\n",
    "\n",
    "def categorical_pdf(x, samples):\n",
    "    n = len(samples)\n",
    "    c = Counter(x)\n",
    "    densities = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        densities[i] = c[samples[i]]\n",
    "        \n",
    "    return densities\n",
    "\n",
    "def calculate_EI(lx, gx):\n",
    "    gx[gx < 0.0001] = 0.0001\n",
    "    EI = lx/gx\n",
    "    return EI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7cecee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "trails = 5\n",
    "\n",
    "\n",
    "fig,axs1 = plt.subplots(nrows=2,ncols=2,figsize=(12,3))\n",
    "for j in range(trails):\n",
    "    hyperparameters, bp,x, y, EI_plot1, EI_plot2,l_x_plot_h1,g_x_plot_h1,l_x_plot_h2,g_x_plot_h2  = tpe2(\"good_range\",gamma=0.25)\n",
    "    losses = hyperparameters[\"loss\"].values.tolist()\n",
    "    loss=[]\n",
    "    for i in range(1,len(losses)):\n",
    "        loss.append(min(losses[:i]))        \n",
    "    axs1[0][0].plot(range(len(losses)-1),loss)   \n",
    "    axs1[0][0].title.set_text(\"Gamma = 0.25\")\n",
    "\n",
    "for j in range(trails):\n",
    "    hyperparameters, bp,x, y, EI_plot1, EI_plot2,l_x_plot_h1,g_x_plot_h1,l_x_plot_h2,g_x_plot_h2  = tpe2(\"good_range\",gamma=0.5)\n",
    "    losses = hyperparameters[\"loss\"].values.tolist()\n",
    "    loss=[]\n",
    "    for i in range(1,len(losses)):\n",
    "        loss.append(min(losses[:i]))        \n",
    "    axs1[0][1].plot(range(len(losses)-1),loss)   \n",
    "    axs1[0][1].title.set_text(\"Gamma = 0.5\")\n",
    "    \n",
    "for j in range(trails):\n",
    "    hyperparameters, bp,x, y, EI_plot1, EI_plot2,l_x_plot_h1,g_x_plot_h1,l_x_plot_h2,g_x_plot_h2  = tpe2(\"good_range\",gamma=0.75)\n",
    "    losses = hyperparameters[\"loss\"].values.tolist()\n",
    "    loss=[]\n",
    "    for i in range(1,len(losses)):\n",
    "        loss.append(min(losses[:i]))        \n",
    "    axs1[1][0].plot(range(len(losses)-1),loss)   \n",
    "    axs1[1][0].title.set_text(\"Gamma = 0.75\")\n",
    "\n",
    "for j in range(trails):\n",
    "    hyperparameters, bp,x, y, EI_plot1, EI_plot2,l_x_plot_h1,g_x_plot_h1,l_x_plot_h2,g_x_plot_h2 = tpe2(\"good_range\",gamma=1)\n",
    "    losses = hyperparameters[\"loss\"].values.tolist()\n",
    "    loss=[]\n",
    "    for i in range(1,len(losses)):\n",
    "        loss.append(min(losses[:i]))        \n",
    "    axs1[1][1].plot(range(len(losses)-1),loss)   \n",
    "    axs1[1][1].title.set_text(\"Gamma = 1\")\n",
    "\n",
    "for ax in axs1.flat:\n",
    "    ax.set(xlabel='Function evaluations', ylabel='Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103fe795",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
