{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fff30387",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from distutils.command import config\n",
    "\n",
    "def random_search(problem, function_evaluations=10, **kwargs):\n",
    "\n",
    "    history = []\n",
    "    configs = []\n",
    "\n",
    "    RANGES = GET_RANGES(problem) \n",
    "\n",
    "    for j in range(function_evaluations):\n",
    "        config={}\n",
    "        \n",
    "        for i in RANGES:\n",
    "            # If there is a condition, check if it holds.\n",
    "            # If not, skip this hyperparameter\n",
    "            if(condition(RANGES, config, i)):\n",
    "                continue\n",
    "            \n",
    "            a = RANGES[i]['range'][0] \n",
    "            b = RANGES[i]['range'][1] \n",
    "            \n",
    "            # If uniform\n",
    "            if(RANGES[i]['sample']==0):\n",
    "                if (RANGES[i][\"type\"] == 0):\n",
    "                    value=np.random.choice(RANGES[i]['range']) \n",
    "                    config[i]=value  \n",
    "                elif (RANGES[i][\"type\"] == 1):\n",
    "                    value=np.random.uniform(a, b) \n",
    "                    config[i]=value\n",
    "                else:\n",
    "                    value=np.random.randint(a, b+1) \n",
    "                    config[i]=value\n",
    "            # Else log        \n",
    "            else:\n",
    "                value=np.random.uniform(np.log(a), np.log(b)) \n",
    "                value = np.exp(value)\n",
    "                if RANGES[i]['type'] == 2:\n",
    "                    value = round(value)\n",
    "                config[i]=value # exponentiate value back \n",
    "        if problem != 'interactive':        \n",
    "            config['nodes_per_layer'] = return_node_list(config)        \n",
    "        configs.append(config)\n",
    "        history.append(GET_CONFIG_PERFORMANCE(config, problem))\n",
    "\n",
    "    return history, configs\n",
    "\n",
    "# Function for checking if hyperparameter has a condition and whether it holds\n",
    "def condition(ranges, config, i):\n",
    "        if('condition' in ranges[i]):\n",
    "            if (ranges[i]['condition'](config) == False):\n",
    "                return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22ee1269",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import GET_CONFIG_PERFORMANCE, GET_RANGES, SampleType, ParamType,normal_dist # make sure to make use of ParamType and SampleType in your code\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from scipy.stats import truncnorm\n",
    "import math\n",
    "\n",
    "\n",
    "def ugly_condition_check(x_star, i): \n",
    "    if 'nlayers' in x_star.keys():\n",
    "        layers = x_star['nlayers']\n",
    "        if i[-1].isdigit():\n",
    "            if int(i[-1]) > layers:\n",
    "                return True\n",
    "\n",
    "\n",
    "def tpe2(problem, function_evaluations=120, random_warmup=30, gamma=1, n=10, **kwargs):\n",
    "\n",
    "    RANGES = GET_RANGES(problem) \n",
    "    \n",
    "    # Initial warm-up using random search\n",
    "    loss,configs=random_search(problem,random_warmup)    \n",
    "    \n",
    "    hyperparameters = to_df(configs, loss)    \n",
    "        \n",
    "    for k in range(function_evaluations):\n",
    "        \n",
    "        good_df, bad_df = good_bad(gamma, hyperparameters)\n",
    "        x_star = {}\n",
    "        \n",
    "        for i in good_df.columns.difference(['loss', 'nodes_per_layer']): \n",
    "            x = good_df[i].dropna().values.tolist()\n",
    "            y = bad_df[i].dropna().values.tolist()\n",
    "            full = x + y\n",
    "            \n",
    "            a = RANGES[i]['range'][0]\n",
    "            b = RANGES[i]['range'][1]\n",
    "                \n",
    "            if(ugly_condition_check(x_star, i)):\n",
    "                 continue\n",
    "            \n",
    "            # If categorical, sample uniform\n",
    "            if RANGES[i]['type'] == 0:\n",
    "                sample = sample_uniform(RANGES[i])\n",
    "                x_star[i] = sample \n",
    "                \n",
    "            else:\n",
    "                if RANGES[i]['sample'] == 1:\n",
    "                    x = np.log(x)\n",
    "                    y = np.log(y)\n",
    "                    full = np.log(full)\n",
    "                    a, b = np.log(a), np.log(b)\n",
    "                    \n",
    "                # Sort because we need the sd to the furthest neighbour\n",
    "                x.sort()                  \n",
    "                y.sort()\n",
    "                full.sort()\n",
    "\n",
    "                std_full = scales(full, a, b)\n",
    "                samples = sample_truncnorm(a, b, full, std_full, n)\n",
    "                \n",
    "                max_sd, max_sd_y = 0, 0\n",
    "\n",
    "                if len(x) > 0:\n",
    "                    max_sd = scales(x, a, b)\n",
    "                if len(y) > 0:\n",
    "                    max_sd_y = scales(y, a, b)\n",
    "\n",
    "                #samples = sample_truncnorm(a, b, x, max_sd, n)\n",
    "                \n",
    "                EI = get_EI(samples, x, y, a, b, max_sd, max_sd_y)\n",
    "\n",
    "                EI_max = np.argmax(EI)\n",
    "                value = samples[EI_max]\n",
    "                if RANGES[i]['sample'] == 1:\n",
    "                    value = np.exp(value)\n",
    "                if RANGES[i]['type'] == 2:\n",
    "                    value = round(value)      \n",
    "                x_star[i] = value\n",
    "                \n",
    "        if problem != 'interactive':\n",
    "            x_star['nodes_per_layer'] = return_node_list(x_star)\n",
    "            \n",
    "        x_star['loss'] = GET_CONFIG_PERFORMANCE(x_star, problem)   \n",
    "        hyperparameters = hyperparameters.append(x_star, ignore_index=True)\n",
    "        \n",
    "    best_hp = hyperparameters.iloc[hyperparameters['loss'].idxmin()]\n",
    "    return best_hp\n",
    "\n",
    "def get_EI(samples, x, y, a, b, max_sd, max_sd_y):\n",
    "    EI = []\n",
    "    for j in range(len(samples)):   \n",
    "        lx = 0\n",
    "        gx = 0\n",
    "        if len(x) > 0:\n",
    "            lx = get_pdf(samples[j], x, a, b, max_sd)     \n",
    "\n",
    "        if len(y) > 0:\n",
    "            gx = get_pdf(samples[j], y, a, b, max_sd_y)\n",
    "        \n",
    "        if gx > 0:\n",
    "            EI.append(lx/gx)\n",
    "        else:\n",
    "            EI.append(lx)\n",
    "    return EI\n",
    "\n",
    "def return_node_list(x):\n",
    "    nodes= []\n",
    "    for i in x.keys():\n",
    "        if 'nodes_in_layer' in i:\n",
    "            nodes.append(x[i])\n",
    "    return nodes\n",
    "        \n",
    "def to_df(configs, loss):\n",
    "\n",
    "    hyper_parameters=pd.DataFrame(columns=[\"configs\",\"loss\"])\n",
    "    hyper_parameters[\"configs\"]=configs\n",
    "    hyper_parameters[\"loss\"]=loss\n",
    "    \n",
    "    hyper_parameters_1 = (hyper_parameters[\"configs\"].apply(pd.Series))\n",
    "    hyper_parameters_1['loss'] = hyper_parameters[\"loss\"]\n",
    "    \n",
    "    \n",
    "    return hyper_parameters_1\n",
    "            \n",
    "# Function for dividing samples into good and bad dataframes    \n",
    "def good_bad(gamma, hyper_parameters):\n",
    "\n",
    "    sorted_df=(hyper_parameters.sort_values(by=[\"loss\"])).reset_index(drop=True)\n",
    "    \n",
    "    index_value=int(gamma*(sorted_df.shape[0]))\n",
    "    \n",
    "    good_df = sorted_df.iloc[:index_value]\n",
    "    bad_df = sorted_df.iloc[index_value:sorted_df.shape[0]]\n",
    "            \n",
    "    return good_df, bad_df\n",
    "\n",
    "def sample_truncnorm(a, b, x, sd, n):\n",
    "    index = np.random.choice(range(len(x)))\n",
    "    a, b = (a - x[index]) / sd[index], (b - x[index]) / sd[index]\n",
    "    samples = stats.truncnorm.rvs(a, b, loc=x[index], scale=sd[index], size=n)\n",
    "    return samples\n",
    "\n",
    "def get_pdf(x_i, x, a, b, sd):\n",
    "    n = len(x)\n",
    "    total = 0\n",
    "    \n",
    "    for i in range(n):\n",
    "        mean = x[i]\n",
    "        sigma = sd[i]\n",
    "        a, b = (a - mean) / sigma, (b - mean) / sigma\n",
    "        total += stats.truncnorm.pdf(x_i, a, b, loc=mean, scale=sigma)\n",
    "       # if error == 'error':\n",
    "       #     print(x_i, a, b, mean, sigma)\n",
    "        \n",
    "    return total/n\n",
    "\n",
    "def scales(x, a, b):\n",
    "    if len(x) > 1:\n",
    "        diff = np.diff(x)\n",
    "    else:\n",
    "        diff = 0\n",
    "    epsilon = (b-a)/min(100,len(x)+2)\n",
    "    scales = []\n",
    "    for i in range(0, len(diff)):\n",
    "        max_ = max(diff[i-1], diff[i], epsilon)\n",
    "        sigma = min(max_, b-a)\n",
    "        scales.append(sigma)        \n",
    "    scales.insert(0,min(max(diff[0], epsilon), b-a))\n",
    "    scales.insert(-1,min(max(diff[-1], epsilon), b-a))\n",
    "    \n",
    "    return scales\n",
    "\n",
    "def sample_uniform(hyperparameter):\n",
    "    sample = np.random.choice(hyperparameter['range'])    \n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "94411893",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hyper1': -11.27072067213108, 'hyper2': 24.66278494863046}\n",
      "{'hyper1': 27.32204195569517, 'hyper2': -12.075825093706367}\n",
      "{'hyper1': -2.8916881964227343, 'hyper2': -3.9619414933890766}\n",
      "{'hyper1': 20.493776618846688, 'hyper2': -16.086472598477812}\n",
      "{'hyper1': -22.263579021246578, 'hyper2': -27.749229675733844}\n",
      "{'hyper1': 14.764399801695937, 'hyper2': 24.74287331545854}\n",
      "{'hyper1': 37.98080299455944, 'hyper2': 17.93708213945372}\n",
      "{'hyper1': -1.395226085709183, 'hyper2': -8.69654567949091}\n",
      "{'hyper1': 6.088328373834962, 'hyper2': 28.531608954614015}\n",
      "{'hyper1': -11.59285089953719, 'hyper2': -0.17130193641611413}\n",
      "{'hyper1': -1.8344344886361625, 'hyper2': 6.0755932931441095}\n",
      "{'hyper1': -27.165561184803344, 'hyper2': 2.9435574339122965}\n",
      "{'hyper1': 20.476628725876942, 'hyper2': 31.22097805025605}\n",
      "{'hyper1': -4.980677145967405, 'hyper2': -0.7241957701426713}\n",
      "{'hyper1': 38.61551060323657, 'hyper2': 24.339997237730657}\n",
      "{'hyper1': 13.309480128317084, 'hyper2': -31.165097690949022}\n",
      "{'hyper1': 15.054339284179328, 'hyper2': -31.167088831438363}\n",
      "{'hyper1': 38.38637324718995, 'hyper2': 36.6363443487202}\n",
      "{'hyper1': -31.871380174039608, 'hyper2': -8.321775096559143}\n",
      "{'hyper1': 32.68652750582885, 'hyper2': -29.324583899492424}\n",
      "{'hyper1': 25.044205652596418, 'hyper2': -26.792740485460378}\n",
      "{'hyper1': 6.155521644921322, 'hyper2': -32.3367237956535}\n",
      "{'hyper1': 33.636882734349626, 'hyper2': -17.05990906965635}\n",
      "{'hyper1': 28.886062582573842, 'hyper2': -23.80379328090541}\n",
      "{'hyper1': -17.632858870248953, 'hyper2': -8.967022708739314}\n",
      "{'hyper1': -37.26186482219533, 'hyper2': 13.01094858534384}\n",
      "{'hyper1': -2.6120669684300424, 'hyper2': 12.493726238309108}\n",
      "{'hyper1': -34.990396552378684, 'hyper2': 31.665290709922417}\n",
      "{'hyper1': -16.47781637757376, 'hyper2': 5.4126264735948695}\n",
      "{'hyper1': -13.636298494734149, 'hyper2': 24.488065548574852}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "hyper1       -1.834434\n",
       "hyper2        6.075593\n",
       "loss     -10313.926922\n",
       "Name: 10, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpe2(problem = 'interactive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc71493",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "multivariate_normal([''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c10873",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_dist(x , mean , sd):\n",
    "    prob_density = (np.pi*sd) * np.exp(-0.5*((x-mean)/sd)**2)\n",
    "    return prob_density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386cb6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ln_loss = -(normal_dist(0.061932, mean=0.01, sd=0.003) + 0.00942477796076938)*106.1032953945969\n",
    "nodes_loss = np.sum((-normal_dist(np.array([283, 45, 84]), mean=256, sd=200)+628.305132314888)*1.2*0.0015915833701941327)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194b85f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ln_loss + nodes_loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
