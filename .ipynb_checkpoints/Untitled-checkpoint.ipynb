{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41399e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mally\\AppData\\Local\\Temp\\ipykernel_8088\\3524297253.py:1: DeprecationWarning: The distutils package is deprecated and slated for removal in Python 3.12. Use setuptools or check PEP 632 for potential alternatives\n",
      "  from distutils.command import config\n"
     ]
    }
   ],
   "source": [
    "from distutils.command import config\n",
    "\n",
    "def random_search(problem, function_evaluations=150, **kwargs):\n",
    "\n",
    "    history = []\n",
    "    configs = []\n",
    "\n",
    "    RANGES = GET_RANGES(problem) \n",
    "\n",
    "    for j in range(function_evaluations):\n",
    "        config={}\n",
    "        \n",
    "        for i in RANGES:\n",
    "            # If there is a condition, check if it holds.\n",
    "            # If not, skip this hyperparameter\n",
    "            if(condition(RANGES, config, i)):\n",
    "                config[i] = math.nan\n",
    "                continue\n",
    "            \n",
    "            a = RANGES[i]['range'][0] \n",
    "            b = RANGES[i]['range'][1] \n",
    "            \n",
    "            # If uniform\n",
    "            if(RANGES[i]['sample']==0):\n",
    "                if (RANGES[i][\"type\"] == 0):\n",
    "                    value=np.random.choice(RANGES[i]['range']) \n",
    "                    config[i]=value  \n",
    "                elif (RANGES[i][\"type\"] == 1):\n",
    "                    value=np.random.uniform(a, b) \n",
    "                    config[i]=value\n",
    "                else:\n",
    "                    value=np.random.randint(a, b+1) \n",
    "                    config[i]=value\n",
    "            # Else log        \n",
    "            else:\n",
    "                value=np.random.uniform(np.log(a), np.log(b)) \n",
    "                value = np.exp(value)\n",
    "                if RANGES[i]['type'] == 2:\n",
    "                    value = round(value)\n",
    "                config[i]=value # exponentiate value back \n",
    "      \n",
    "        configs.append(config)\n",
    "        history.append(GET_CONFIG_PERFORMANCE(config, problem))\n",
    "\n",
    "    return history, configs\n",
    "\n",
    "# Function for checking if hyperparameter has a condition and whether it holds\n",
    "def condition(ranges, config, i):\n",
    "        if('condition' in ranges[i]):\n",
    "            if (ranges[i]['condition'](config) == False):\n",
    "                return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a38896fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import GET_CONFIG_PERFORMANCE, GET_RANGES, SampleType, ParamType,normal_dist # make sure to make use of ParamType and SampleType in your code\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from scipy.stats import truncnorm\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# Check if current hyperparameter is active, specifically for nlayers\n",
    "def condition_check(x_star, i): \n",
    "    if 'nlayers' in x_star.keys():\n",
    "        layers = x_star['nlayers']\n",
    "        if i[-1].isdigit():\n",
    "            if int(i[-1]) > layers:\n",
    "                return True\n",
    "\n",
    "# n = number of candidate samples\n",
    "def tpe2(problem, function_evaluations=150, random_warmup=10, gamma=0.5, n=10, **kwargs):\n",
    "\n",
    "    RANGES = GET_RANGES(problem) \n",
    "    \n",
    "    # Initial warm-up using random search\n",
    "    loss,configs=random_search(problem,random_warmup)    \n",
    "    \n",
    "    hyperparameters = to_df(configs, loss)    \n",
    "        \n",
    "    for k in range(function_evaluations):\n",
    "        \n",
    "        good_df, bad_df = good_bad(gamma, hyperparameters)\n",
    "        # Initialize best found configuration\n",
    "        x_star = {}\n",
    "        \n",
    "        # Iterate through each hyperparameter\n",
    "        for i in good_df.columns.difference(['loss']): \n",
    "            # Seperate into good and bad samples\n",
    "            x = good_df[i].dropna().values.tolist()\n",
    "            y = bad_df[i].dropna().values.tolist()\n",
    "            # Add back together for sampling\n",
    "            full = x + y\n",
    "            # Define truncation boundaries\n",
    "            a = RANGES[i]['range'][0]\n",
    "            b = RANGES[i]['range'][1]\n",
    "            # Check if current hyperparamter is active    \n",
    "            if(condition_check(x_star, i)):\n",
    "                x_star[i] = math.nan\n",
    "                continue\n",
    "            \n",
    "            # If categorical\n",
    "            if RANGES[i]['type'] == 0:\n",
    "                samples = sample_uniform(RANGES[i], n)\n",
    "                # Calculate probability density of the samples\n",
    "                lx = categorical_pdf(x, samples)\n",
    "                gx = categorical_pdf(y, samples)\n",
    "                EI = calculate_EI(lx, gx)\n",
    "                EI_max = np.argmax(EI)\n",
    "                value = samples[EI_max]\n",
    "                x_star[i] = value\n",
    "                \n",
    "            else:\n",
    "                # If sample type is log-unfirom\n",
    "                if RANGES[i]['sample'] == 1:\n",
    "                    x = np.log(x)\n",
    "                    y = np.log(y)\n",
    "                    full = np.log(full)\n",
    "                    a, b = np.log(a), np.log(b)\n",
    "                    \n",
    "                # Sort because we need the standard deviation to the furthest neighbour\n",
    "                x.sort()                  \n",
    "                y.sort()\n",
    "                full.sort()\n",
    "                # Calculate sigma for getting the density from the Gaussians\n",
    "                std_full = scales(full, a, b)\n",
    "                # Sample from truncated gaussians\n",
    "                samples = sample_truncnorm(a, b, full, std_full, n)\n",
    "                # In case l(x) or g(x) does not contain samples: the sigma is 0\n",
    "                max_sd, max_sd_y = 0, 0\n",
    "                if len(x) > 0:\n",
    "                    max_sd = scales(x, a, b)\n",
    "                if len(y) > 0:\n",
    "                    max_sd_y = scales(y, a, b)\n",
    "                # Calculate EI\n",
    "                EI = get_EI(samples, x, y, a, b, max_sd, max_sd_y, gamma)\n",
    "                EI_max = np.argmax(EI)\n",
    "                value = samples[EI_max]\n",
    "                # If sample type is log-uniform, exponentiate\n",
    "                if RANGES[i]['sample'] == 1:\n",
    "                    value = np.exp(value)\n",
    "                # If hp type is int, round\n",
    "                if RANGES[i]['type'] == 2:\n",
    "                    value = round(value)      \n",
    "                x_star[i] = value\n",
    "        # Calculate loss and append to observations\n",
    "        x_star['loss'] = GET_CONFIG_PERFORMANCE(x_star, problem) \n",
    "        hyperparameters = hyperparameters.append(x_star, ignore_index=True)            \n",
    "    # Seperate all found hyperparameters for plotting EI, l(x) and g(x)\n",
    "    x_final, y_final = good_bad(gamma, hyperparameters)\n",
    "    EI_plot1 = plot_EI(x_final.iloc[:,0].values,y_final.iloc[:,0].values, a, b, gamma)\n",
    "    EI_plot2 = plot_EI(x_final.iloc[:,1].values, y_final.iloc[:,1].values, a, b, gamma)\n",
    "    \n",
    "    l_x_plot_h1 = pdf_array(x_final.iloc[:,0].values,a,b)\n",
    "    l_x_plot_h2 = pdf_array(x_final.iloc[:,1].values,a,b)\n",
    "    g_x_plot_h1 = pdf_array(y_final.iloc[:,0].values,a,b)\n",
    "    g_x_plot_h2 = pdf_array(y_final.iloc[:,1].values,a,b)\n",
    "    \n",
    "    best_hp = hyperparameters.iloc[hyperparameters['loss'].idxmin()]\n",
    "    return hyperparameters, best_hp, x_final, y_final, EI_plot1, EI_plot2,l_x_plot_h1,g_x_plot_h1,l_x_plot_h2,g_x_plot_h2\n",
    "\n",
    "# Returns an array with the values for EI\n",
    "def plot_EI(x, y, a, b, gamma):\n",
    "    space = np.linspace(a, b, 100)\n",
    "    l_x = pdf_array(x, a, b)\n",
    "    g_x = pdf_array(y, a, b)\n",
    "    # If a value in g(x) == 0, divide by 1\n",
    "    # So i.e: if a samples hyperparameter is not in g(x), its EI = its pd in l(x)\n",
    "    g_x[g_x == 0] = 1\n",
    "    plot = (gamma + (1-gamma)*(l_x/g_x))\n",
    "    return plot\n",
    "\n",
    "# Returns an array with the values for a pdf\n",
    "def pdf_array(x, a, b):\n",
    "    scales_ = []\n",
    "    space = np.linspace(a, b, 100)\n",
    "    scales_ = scales(x, a, b)\n",
    "    array = np.zeros_like(space)\n",
    "    # Iterate through each sample\n",
    "    for i in range(len(x)):\n",
    "        dist = truncnorm(a, b,loc=x[i], scale=scales_[i])\n",
    "        # Get pdf values for its truncated Gaussian \n",
    "        array += dist.pdf(space)\n",
    "    return array\n",
    "\n",
    "# Get EI for a single value of a hyperparameter\n",
    "def get_EI(samples, x, y, a, b, max_sd, max_sd_y, gamma):\n",
    "    EI = []\n",
    "    for j in range(len(samples)):   \n",
    "        # Set the density to 1, incase l(x) and/or g(x) is zero\n",
    "        pd_lx = 0\n",
    "        pd_gx = 1\n",
    "        if len(x) > 0:\n",
    "            pd_lx = get_pdf(samples[j], x, a, b, max_sd)     \n",
    "        if len(y) > 0:\n",
    "            pd_gx = get_pdf(samples[j], y, a, b, max_sd_y)\n",
    "        if pd_gx == 0:\n",
    "            pd_gx = 1\n",
    "        # Calculate EI\n",
    "        value = (gamma + (1-gamma)*(pd_lx/pd_gx))\n",
    "        EI.append(value)\n",
    "    return EI\n",
    "\n",
    "def return_node_list(x):\n",
    "    nodes= []\n",
    "    for i in x.keys():\n",
    "        if 'nodes_in_layer' in i:\n",
    "            nodes.append(x[i])\n",
    "    return nodes\n",
    "        \n",
    "def to_df(configs, loss):\n",
    "\n",
    "    hyper_parameters=pd.DataFrame(columns=[\"configs\",\"loss\"])\n",
    "    hyper_parameters[\"configs\"]=configs\n",
    "    hyper_parameters[\"loss\"]=loss\n",
    "    \n",
    "    hyper_parameters_1 = (hyper_parameters[\"configs\"].apply(pd.Series))\n",
    "    hyper_parameters_1['loss'] = hyper_parameters[\"loss\"]\n",
    "    \n",
    "    \n",
    "    return hyper_parameters_1\n",
    "            \n",
    "# Function for dividing samples into good and bad dataframes    \n",
    "def good_bad(gamma, hyper_parameters):\n",
    "\n",
    "    sorted_df=(hyper_parameters.sort_values(by=[\"loss\"])).reset_index(drop=True)\n",
    "    \n",
    "    index_value=int(gamma*(sorted_df.shape[0]))\n",
    "    \n",
    "    good_df = sorted_df.iloc[:index_value]\n",
    "    bad_df = sorted_df.iloc[index_value:sorted_df.shape[0]]\n",
    "            \n",
    "    return good_df, bad_df\n",
    "\n",
    "def sample_truncnorm(a, b, x, sd, n):\n",
    "    index = np.random.choice(range(len(x)))\n",
    "    a, b = (a - x[index]) / sd[index], (b - x[index]) / sd[index]\n",
    "    samples = stats.truncnorm.rvs(a, b, loc=x[index], scale=sd[index], size=n)\n",
    "    return samples\n",
    "\n",
    "def get_pdf(x_i, x, a, b, sd):\n",
    "    n = len(x)\n",
    "    total = 0\n",
    "    \n",
    "    for i in range(n):\n",
    "        mean = x[i]\n",
    "        sigma = sd[i]\n",
    "        a, b = (a - mean) / sigma, (b - mean) / sigma\n",
    "        total += stats.truncnorm.pdf(x_i, a, b, loc=mean, scale=sigma)\n",
    "       # if error == 'error':\n",
    "       #     print(x_i, a, b, mean, sigma)\n",
    "        \n",
    "    return total/n\n",
    "\n",
    "def scales(x, a, b):\n",
    "    if len(x) > 1:\n",
    "        diff = np.diff(x)\n",
    "    else:\n",
    "        diff = [0]\n",
    "    epsilon = (b-a)/min(100,len(x)+2)\n",
    "    scales = []\n",
    "    for i in range(0, len(diff)):\n",
    "        max_ = max(diff[i-1], diff[i], epsilon)\n",
    "        sigma = min(max_, b-a)\n",
    "        scales.append(sigma)        \n",
    "    scales.insert(0,min(max(diff[0], epsilon), b-a))\n",
    "    scales.insert(-1,min(max(diff[-1], epsilon), b-a))\n",
    "    \n",
    "    return scales\n",
    "\n",
    "def sample_uniform(hyperparameter, n):\n",
    "    sample = np.random.choice(hyperparameter['range'], n)    \n",
    "    return sample\n",
    "\n",
    "def normal_dist(x , mean , sd):\n",
    "    prob_density = (np.pi*sd) * np.exp(-0.5*((x-mean)/sd)**2)\n",
    "    return prob_density\n",
    "\n",
    "def categorical_pdf(x, samples):\n",
    "    n = len(samples)\n",
    "    c = Counter(x)\n",
    "    densities = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        densities[i] = c[samples[i]]\n",
    "        \n",
    "    return densities\n",
    "\n",
    "def calculate_EI(lx, gx):\n",
    "    gx[gx < 0.0001] = 0.0001\n",
    "    EI = lx/gx\n",
    "    return EI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a278c397",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Series.sort_values() got an unexpected keyword argument 'by'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [4], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m fig,axs1 \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(nrows\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,ncols\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m20\u001b[39m,\u001b[38;5;241m3\u001b[39m))\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(trails):\n\u001b[1;32m----> 9\u001b[0m     hyperparameters, bp,x, y, EI_plot1, EI_plot2,l_x_plot_h1,g_x_plot_h1,l_x_plot_h2,g_x_plot_h2  \u001b[38;5;241m=\u001b[39m \u001b[43mtpe2\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgood_range\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mrandom_warmup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     losses \u001b[38;5;241m=\u001b[39m hyperparameters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m     11\u001b[0m     loss\u001b[38;5;241m=\u001b[39m[]\n",
      "Cell \u001b[1;32mIn [2], line 33\u001b[0m, in \u001b[0;36mtpe2\u001b[1;34m(problem, function_evaluations, random_warmup, gamma, n, **kwargs)\u001b[0m\n\u001b[0;32m     29\u001b[0m hyperparameters \u001b[38;5;241m=\u001b[39m to_df(configs, loss)    \n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(function_evaluations):\n\u001b[1;32m---> 33\u001b[0m     good_df, bad_df \u001b[38;5;241m=\u001b[39m \u001b[43mgood_bad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m# Initialize best found configuration\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     x_star \u001b[38;5;241m=\u001b[39m {}\n",
      "Cell \u001b[1;32mIn [2], line 176\u001b[0m, in \u001b[0;36mgood_bad\u001b[1;34m(gamma, hyper_parameters)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgood_bad\u001b[39m(gamma, hyper_parameters):\n\u001b[1;32m--> 176\u001b[0m     sorted_df\u001b[38;5;241m=\u001b[39m(\u001b[43mhyper_parameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mby\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mloss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    178\u001b[0m     index_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(gamma\u001b[38;5;241m*\u001b[39m(sorted_df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]))\n\u001b[0;32m    180\u001b[0m     good_df \u001b[38;5;241m=\u001b[39m sorted_df\u001b[38;5;241m.\u001b[39miloc[:index_value]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deep_learning_a0\\lib\\site-packages\\pandas\\util\\_decorators.py:317\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    312\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    313\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    314\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    315\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(inspect\u001b[38;5;241m.\u001b[39mcurrentframe()),\n\u001b[0;32m    316\u001b[0m     )\n\u001b[1;32m--> 317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mTypeError\u001b[0m: Series.sort_values() got an unexpected keyword argument 'by'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2000x300 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "trails = 5\n",
    "\n",
    "\n",
    "fig,axs1 = plt.subplots(nrows=2,ncols=2,figsize=(20,3))\n",
    "for j in range(trails):\n",
    "    hyperparameters, bp,x, y, EI_plot1, EI_plot2,l_x_plot_h1,g_x_plot_h1,l_x_plot_h2,g_x_plot_h2  = tpe2(\"good_range\",random_warmup=1)\n",
    "    losses = hyperparameters[\"loss\"].values.tolist()\n",
    "    loss=[]\n",
    "    for i in range(1,len(losses)):\n",
    "        loss.append(min(losses[:i]))        \n",
    "    axs1[0][0].plot(range(len(losses)-1),loss)   \n",
    "    axs1[0][0].title.set_text(\"Random Warmup = 0\")\n",
    "\n",
    "for j in range(trails):\n",
    "    hyperparameters, bp,x, y, EI_plot1, EI_plot2,l_x_plot_h1,g_x_plot_h1,l_x_plot_h2,g_x_plot_h2  = tpe2(\"good_range\",random_warmup=10)\n",
    "    losses = hyperparameters[\"loss\"].values.tolist()\n",
    "    loss=[]\n",
    "    for i in range(1,len(losses)):\n",
    "        loss.append(min(losses[:i]))        \n",
    "    axs1[0][1].plot(range(len(losses)-1),loss)   \n",
    "    axs1[0][1].title.set_text(\"Random Warmup = 10\")\n",
    "    \n",
    "for j in range(trails):\n",
    "    hyperparameters, bp,x, y, EI_plot1, EI_plot2,l_x_plot_h1,g_x_plot_h1,l_x_plot_h2,g_x_plot_h2  = tpe2(\"good_range\",random_warmup=20)\n",
    "    losses = hyperparameters[\"loss\"].values.tolist()\n",
    "    loss=[]\n",
    "    for i in range(1,len(losses)):\n",
    "        loss.append(min(losses[:i]))        \n",
    "    axs1[1][1].plot(range(len(losses)-1),loss)   \n",
    "    axs1[1][1].title.set_text(\"Random Warmup = 20\")\n",
    "    \n",
    "\n",
    "for ax in axs1.flat:\n",
    "    ax.set(xlabel='Function evaluations', ylabel='Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67797c4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
